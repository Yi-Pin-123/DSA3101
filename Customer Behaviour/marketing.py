# -*- coding: utf-8 -*-
"""Marketing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dQHfte1soa1ut7DLsXh0z3CV1Fu3uNL6

# **Authenticate and set up BigQuery client:** âœ”
"""

# Commented out IPython magic to ensure Python compatibility.
# Configuration for Google Colab

# !pip install google-cloud-bigquery
# !pip install rich
# !pip install pandas
# !pip install seaborn
# !pip install matplotlib

from google.colab import auth
from google.cloud import bigquery
import pandas as pd
import seaborn as sns
import math
import matplotlib.pyplot as plt
from IPython.display import clear_output, display
from google.colab import output
import time
import numpy as np
import os

from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.text import Text
from rich.align import Align
from rich import box

# Initialize Rich console
console = Console()

# Ignore warnings
import warnings
warnings.filterwarnings("ignore")

# Set up matplotlib for inline plotting in Colab
# %matplotlib inline

# Configure pandas display options
pd.set_option('display.max_columns', 100)
pd.set_option('display.max_rows', 100)

# Clear the output to remove installation messages
clear_output()


#Animation
with console.status("[bold green]Configuring...") as status:

    time.sleep(2)
    status.update("[bold green]Configuration complete!")
    time.sleep(1)

console.print(Align("[bold green]Configuration complete![/bold green]", align="center"))

# Authenticate and create BigQuery client
auth.authenticate_user()
project_id = "marketing-435421"  #------------------------------------------->Attention

# Path to the service account JSON key file
key_path = "marketing-435421-8ce10b942394.json"

# Set the GOOGLE_APPLICATION_CREDENTIALS environment variable
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = key_path
client = bigquery.Client(project=project_id)

console.print(Panel(f"[bold green]Current project ID:[/bold green] {project_id}"))

test_query = """
SELECT COUNT(*) as count
FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_20210131`
"""

try:
    df = client.query(test_query).to_dataframe()

    # Create a Rich table to display the result
    table = Table(title="Test Query Result")
    table.add_column("Count", style="cyan")

    for _, row in df.iterrows():
        table.add_row(str(row['count']))

    console.print(Panel(table, expand=False))

except Exception as e:
    console.print(Panel(f"[bold red]An error occurred:[/bold red] {str(e)}", expand=False))

query = """
SELECT *
FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_20210131`
"""
df = client.query(query).to_dataframe()

# flatten nested columns , each row to dict
df = pd.json_normalize(df.to_dict(orient='records'))

# find columns with missing values
missing_data = df.isnull().sum()
print(missing_data[missing_data > 0])

total_rows = len(df)

# calculate percentage of missing values
missing_data = df.isnull().sum()
percentage_missing = (missing_data / total_rows) * 100

# missing report
missing_report = pd.DataFrame({
    'Column': missing_data.index,
    'Missing Values': missing_data.values,
    'Percentage Missing': percentage_missing.values
}).sort_values(by='Percentage Missing', ascending=False)

print("Missing Report:")
print(missing_report)

# drop columns with more than 50% missing values
df.drop(columns=missing_report[missing_report['Percentage Missing'] > 50]['Column'], inplace=True)

# leftover missing data
left_missing = df.isnull().sum()
print(left_missing[left_missing > 0])

# replace values with median timestamp or should we drop?
df['user_first_touch_timestamp'].fillna(df['user_first_touch_timestamp'].median(), inplace=True)

# replace missing values with the most common language
df['device.language'].fillna(df['device.language'].mode()[0], inplace=True)

# check no more missing data
missing_data = df.isnull().sum()
print(missing_data>0)

# check duplicates
for col in df.columns:
    if df[col].apply(lambda x: isinstance(x, (list, dict, np.ndarray))).any():
        print(f"Column '{col}' contains unhashable types")

# copy of df to check any duplicates
df_copy = df.copy()

# convert unhashable columns to strings in the copy, then check duplicates
df_copy = df_copy.applymap(lambda x: str(x) if isinstance(x, (list, dict, np.ndarray)) else x)
duplicate_rows = df_copy[df_copy.duplicated()]
print(len(duplicate_rows))

# no duplicate rows in df